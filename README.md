# VectorStoreIntro
A Python project implementing a simple LLM-based Retrieval-Augmented Generation (RAG) system with Chroma vectorstore and OpenAI embeddings.

---

Integrate a ChatOpenAI model for generating responses based on retrieved documents.
Add a larger, more diverse dataset.
Implement more advanced RAG features, such as prompt templates and chaining.


---

# LLM RAG Example Project
This project demonstrates a simple **Retrieval-Augmented Generation (RAG)** pipeline using OpenAI embeddings and the Chroma vectorstore in Python.

## Features
- Converts documents into embeddings using OpenAIEmbeddings.
- Stores documents in a Chroma vectorstore for similarity search.
- Supports semantic search queries against a small sample document corpus.
- Ready for integrating a generative model to produce RAG-style answers.

## Installation
```bash
pip install -r requirements.txt
